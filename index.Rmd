---
title: "Big Data, Big Problems?"
subtitle: "Insights from Teaching Web Scraping"
author: "Fabian Gülzau"
institute: "HU Berlin"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  xaringan::moon_reader:
    css: xaringan-themer.css
    lib_dir: libs
    nature:
      highlightStyle: github
      highlightLines: true
      countIncrementalSlides: false
---

```{r setup, include = FALSE}
options(htmltools.dir.version = FALSE)
```


```{r xaringan-themer, include = FALSE, warning = FALSE}
library(xaringanthemer)
style_mono_accent(
  base_color = "#1c5253",
  header_font_google = google_font("Josefin Sans"),
  text_font_google   = google_font("Montserrat", "300", "300i"),
  code_font_google   = google_font("Fira Mono")
)
```

# Content

1. Experience
  + Curriculum
  + Issues
  + Approach
2. Developments in Web Scraping
3. Suggestions

---

# Experience

- Teaching primers and one-day workshops on web scraping
  - postgraduate level and faculty
- Workshops based on R
- Participants with basic/intermediate programming skills

---

# Curriculum

```{r curriculum, echo = FALSE, eval = TRUE, warning = FALSE, message = FALSE, fig.width = 10, fig.height = 6, dpi = 300}
library(tidyverse)
library(lubridate)

curriculum.df <- tibble(
  task = factor(
    c("Introduction", "Web technologies", "Application in R", "Break",
      "Application in R", "Advanced topics", "Legalities & ethics"),
    levels = c("Introduction", "Web technologies", "Application in R", "Break",
               "Advanced topics", "Legalities & ethics")),
  start = c(hm("9:00"), hm("9:30"), hm("11:00"), hm("12:00"), hm("13:00"), 
            hm("15:00"), hm("16:30")),
  end = c(hm("9:30"), hm("11:00"), hm("12:00"), hm("13:00"), hm("15:00"), 
          hm("16:30"), hm("17:30")),
  pause = c(0, 0, 0, 1, 0, 0, 0))

ggplot(curriculum.df, aes(x = fct_rev(task), xend = fct_rev(task), 
                          y = start, yend = end, colour = factor(pause))) + 
  geom_segment(size = 10, show.legend = FALSE) + 
  coord_flip() +
  labs(x = "", y = "") +
  scale_y_time(labels = function(x)stringr::str_sub(format(x), end = -4L)) +
  theme_xaringan(background_color = "#FFFFFF") +
  scale_colour_manual(values = c("#1c5253", "#cccccc"))
```

---

# Issues

.pull-left[
- Time constraints (max. 1h on legalities/ethics)
- Multiple third-parties
  - Website operator
  - Users
- Many cases & tools
  - Social media
  - Corporate data
  - APIs, websites...
]

.pull-right[
```{r stakeholder, eval = TRUE, echo = FALSE, out.width = "80%"}
DiagrammeR::grViz("
digraph stakeholders {

graph [overlap = true, fontsize = 10, fontname = Montserrat]

node [shape = box]
nodeA [label = 'Researcher'];
nodeB [label = 'Web\noperator'];
nodeC [label = 'User']

nodeA->nodeB [label='Legalities', fontsize = 7];
nodeA->nodeC [label=' Ethics', fontsize = 7]
}")
```
]

---

# Approach

> "Big data? Cheap. Lawyers? Not so much."

— Pete Warden (cit. in Mitchell 2015. Web Scraping with Python) 

- Sensitize participants (ToS, non-reactive data)
- Contact universities' ethics commission
- Introduce tools (e.g. `robotstxt`)